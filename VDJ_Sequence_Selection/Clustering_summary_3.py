'''
Script to transfer the output generated by the Clustering scripts to a dataset
'''

import pandas as pd
import numpy as np
import os

def load_labels(file_prefix, file_path_labels, file_data, cluster_range, n_sequences):
    '''
    Function to load the clustering output into a proper summarization file format;

    :param file_prefix: the prefix of the files to be loaded in the file path
    :param file_path: the path that contains the files with the indices of the sequences and the corr.
    cluster label
    :param cluster_range: range of cluster numbers that used in the clustering script
    :param n_sequences: number of sequences that were clustered
    :return: dataframe that contains the following columns: ['ReadID'], ['Dataset'], ['Boost'],
    ClusterNr_[cluster range], ['CDR3']
    '''
    # set the data names to load
    file_names = [str(file_prefix) + str(i) for i in cluster_range]

    # define the column names for the summarization data frame
    cols = ['ReadID'] + ['Dataset'] + ['Boost'] + ['ClusterNr_' + str(i) for i in cluster_range] + ['CDR3_AA']
    # initialize the dataframe
    df = pd.DataFrame(index=range(n_sequences), columns=cols, dtype=np.int32)

    # set the counter to access the right column of the dataframe
    i = 3
    # Load the data into the dataframe
    for file in file_names:
        data = pd.read_csv(str(file_path_labels + file + '.txt'), index_col=0, sep='\t', low_memory=True,
                           dtype=np.int32)
        df[df.columns[i]] = data
        i += 1

    # add the entries of the columns in the other columns from the file that contains the information about ReadID,
    # Dataset, Boost, and also the CDR3
    df['ReadID'] = pd.read_csv(file_data, sep='\t', usecols=['ReadID'])
    df['Dataset'] = pd.read_csv(file_data, sep='\t', usecols=['Dataset'])
    df['Boost'] = pd.read_csv(file_data, sep='\t', usecols=['Boost'])
    df['CDR3_AA'] = pd.read_csv(file_data, sep='\t', usecols=['CDR3_AA'])

    return df

def dict_target_cluster_seq_nr(linkage, cluster_input, cluster_range, tar_seq_index, file, print_out = False,
                               write_summary = False):
    '''
    Function to store a dataframe of the sequences that occur in the same cluster as the binder sequence in a
    dictionary with the keys of the cluster range and linkage
    :param cluster_input: dataframe from load_labels()
    :param cluster_range: range of cluster numbers that used in the clustering script
    :param tar_seq_index: index of the target sequence
    :return: dictionary with dataframes stored in the keys of the respective linkage and cluster number
    '''

    # Filter for the sequences in the cluster of the target sequence
    data_names = ['tar_cluster_' + str(linkage) + '_' + str(i) for i in cluster_range]


    # initialize list to store the dataframes of all the clusters
    dict = {}

    j = cluster_range
    for i in range(len(data_names)):

        # initialize dataframe to store data
        tar_cluster = cluster_input[cluster_input[str('ClusterNr_'+str(j[i]))] == cluster_input.iloc[tar_seq_index, i+3]]

        # reset index
        tar_cluster.reset_index(drop=True, inplace=True)
        # store the dataframe in the dictionary
        dict[data_names[i]] = tar_cluster

    # print number of sequences in the target cluster
    if print_out == True:
        print('Nr. of sequences in target cluster,', str(linkage), 'linkage:')
        for i in range(len(data_names)):
            print(linkage, cluster_range[i], ':', len(dict[data_names[i]]))

    if write_summary == True:
        with open(file, 'w') as f_out:
            f_out.write("Nr. of sequences in target cluster, {} linkage:\n".format(linkage))
            for i in range(len(data_names)):
                f_out.write("{} {}: {}\n".format(linkage, cluster_range[i], len(dict[data_names[i]])))

    return dict




#### SET INPUT FILE PATHS
abs_path = 'D:/Dokumente/Masterarbeit/Lena/VDJ_Sequence_Selection'



#### set file paths

# set file path for the data of the average linkage (CDR3 length filtered Clustering)
file_path_filt = abs_path+'/data/Clustering/hierarchical_clustering_filt/Cluster_labels/'
# set the filepath to the original file of the data of all the length-filtered CDR3 sequences
file_data_filt = abs_path+'/data/Filtered_files/data_uniq_length_CDR3.txt'
# save the summary clustering file
save_bool_filt = True

# output path for the clustering
output_path_filt = abs_path+'/data/Clustering/hierarchical_clustering_filt/'
# create output path if it doesn't exist
if not os.path.exists(output_path_filt):
    os.makedirs(output_path_filt)

# output path to the summary folder
output_path_summary = abs_path+'/data/Clustering/Summary/'
# create output path if it doesn't exist
if not os.path.exists(output_path_summary):
    os.makedirs(output_path_summary)


# set path to AFFINITY PORPAGATION clustering file
file_path_AP = abs_path+'/data/Clustering/AP_clustering/Cluster_labels/'




# ####### NON FILTERED DATA ---> did not work very well!
#
# #  (1) Load the clustering labels (average linkage) in a dataframe
# label_data_names = ['labels_cluster_average' + str(i) for i in range(50, 1000, 50)]
# cols = ['ReadID']+['Dataset']+['Boost']+['ClusterNr_'+str(i) for i in range(50, 1000, 50)]+['CDR3_AA']
# labels_all_average = pd.DataFrame(index=range(27077), columns=cols, dtype=np.int32)
#
# data = pd.DataFrame()
# i=3
# for file in label_data_names:
#     data = pd.read_csv(str(file_path_filt + file + '.txt'), index_col=0, sep='\t', low_memory=True,
#                        dtype=np.int32)
#     labels_all_average[labels_all_average.columns[i]] = data
#     i=i+1
#
# # in labels we have a dataframe with all the Sequence indices and the according clusters
# # we now want to add a column as the ReadIDs, Dataset and boost
# # therefore we read the columns of the file, where all the unique sequences are
#
# file_path2 = './data/Clustering/'
# labels_all_average['ReadID'] = pd.read_csv(str(file_path2+'data_uniqCDR3.txt'), sep = '\t', usecols=['ReadID'])
# labels_all_average['Dataset'] = pd.read_csv(str(file_path2+'data_uniqCDR3.txt'), sep = '\t', usecols=['Dataset'])
# labels_all_average['Boost'] = pd.read_csv(str(file_path2+'data_uniqCDR3.txt'), sep = '\t', usecols=['Boost'])
# labels_all_average['CDR3_AA'] = pd.read_csv(str(file_path2+'data_uniqCDR3.txt'), sep = '\t', usecols=['CDR3_AA'])
# # save the file with the clusterlabels
# labels_all_average.to_csv(str(file_path+'labels_summary_all_average.txt'), sep = '\t')
#
# # Filter for the sequences in the cluster of the target sequence
# tar_cluster_names_all_av = ['tar_cluster_all_average_'+str(i) for i in range(50, 1000, 50)]
#
# j = range(50, 1000, 50)
# for i in range(len(tar_cluster_names_all_av)):
#     locals()[tar_cluster_names_all_av[i]] = pd.DataFrame(columns=cols)
#     tar_cluster = labels_all_average[labels_all_average[str('ClusterNr_'+str(j[i]))] == labels_all_average.iloc[17358, i+3]]
#     locals()[tar_cluster_names_all_av[i]] = tar_cluster
# # print number of sequences in the target cluster
# print('Nr. of sequences in target cluster, all CDR3s average linkage (from 50-950 clusters):')
# for i in range(len(tar_cluster_names_all_av)):
#     print(len(locals()[tar_cluster_names_all_av[i]]))
#
# # save certain data of interest;
# tar_cluster_all_average_550.to_csv(str(file_path2 + '/Summary/average_550_nonfilt/average_labels_550.txt'), sep = '\t')
#
#
#
#
# # (2) Load the clustering labels (complete linkage) in a dataframe
# label_data_all = ['labels_cluster_complete' + str(i) for i in range(50, 1000, 50)]
# cols = ['ReadID']+['Dataset']+['Boost']+['ClusterNr_'+str(i) for i in range(50, 1000, 50)]+['CDR3_AA']
# labels_all_complete = pd.DataFrame(index=range(27077), columns=cols, dtype=np.int32)
# file_path = './data/Clustering/Clustering_dist_matrix/'
# data = pd.DataFrame()
# i=3
# for file in label_data_all:
#     data = pd.read_csv(str(file_path + 'Cluster_labels_2/' + file + '.txt'), index_col=0, sep='\t', low_memory=True,
#                        dtype=np.int32)
#     labels_all_complete[labels_all_complete.columns[i]] = data
#     i=i+1
#
# # in labels we have a dataframe with all the Sequence indices and the according clusters
# # we now want to add a column as the ReadIDs, Dataset and boost
# # therefore we read the columns of the file, where all the unique/united sequences are
#
# file_path2 = './data/Clustering/'
# labels_all_complete['ReadID'] = pd.read_csv(str(file_path2+'data_uniq_length_CDR3.txt'), sep = '\t', usecols=['ReadID'])
# labels_all_complete['Dataset'] = pd.read_csv(str(file_path2+'data_uniq_length_CDR3.txt'), sep = '\t', usecols=['Dataset'])
# labels_all_complete['Boost'] = pd.read_csv(str(file_path2+'data_uniq_length_CDR3.txt'), sep = '\t', usecols=['Boost'])
# labels_all_complete['CDR3_AA'] = pd.read_csv(str(file_path2+'data_uniq_length_CDR3.txt'), sep = '\t', usecols=['CDR3_AA'])
# # save the file with the clusterlabels
# labels_all_complete.to_csv(str(file_path+'labels_summary_all_complete.txt'), sep = '\t')
#
# tar_cluster_names_all_com = ['tar_cluster_all_complete_'+str(i) for i in range(50, 1000, 50)]
#
# j = range(50, 1000, 50)
# for i in range(len(tar_cluster_names_all_com)):
#     locals()[tar_cluster_names_all_com[i]] = pd.DataFrame(columns=cols)
#     tar_cluster = labels_all_complete[labels_all_complete[str('ClusterNr_'+str(j[i]))] == labels_all_complete.iloc[17358, i+3]]
#     locals()[tar_cluster_names_all_com[i]] = tar_cluster
# # print number of sequences in the target cluster
# print('Nr. of sequences in target cluster, all CDR3s complete linkage (from 50-950 clusters):')
# for i in range(len(tar_cluster_names_all_com)):
#     print(len(locals()[tar_cluster_names_all_com[i]]))
#
# # save certain data of interest;
# tar_cluster_all_complete_100.to_csv(str(file_path2 + 'Summary/complete_100_nonfilt/complete_labels_100.txt'), sep = '\t')
#
#





###################### CDR3 LENGTH FILTERED DATA ## number of defined clusters--> range(20, 300, 20)

# (1) Load the clustering labels (average linkage) in a dataframe
label_data_average = load_labels('labels_cluster_average', file_path_filt, file_data_filt, range(20, 300, 20), 1760)

# save a file of all sequences and the respective cluster lables
if save_bool_filt == True:
    label_data_average.to_csv(output_path_filt+'labels_summary_filt_average.txt', sep = '\t')

# create dictionary with all cluster numbers and the data with the sequences that occur in the target cluster with
# the binder sequence
dict_tar_un_average = dict_target_cluster_seq_nr('average', label_data_average, range(20, 300, 20), 1069,
                                                 str(output_path_filt + 'Nr_seq_av_filt.txt'), print_out = True, write_summary=False)


### NOTE ###
# average linkage with 60 cluster centers was chosen for further analysis as the
# target cluster had ca. 200 sequences; see nr_seq_av_filt.txt file
###########

# save data of the cluster of interest (cluster that contains the binder sequence) in the clustering summary folder
dict_tar_un_average["tar_cluster_average_60"].to_csv(output_path_summary + 'average_60_filt/average_60_target_cluster.txt', sep = '\t')




# (2) Load the clustering labels (complete linkage) in a dataframe
label_data_un_complete = load_labels('labels_cluster_complete', file_path_filt, file_data_filt, range(20, 300, 20), 1760)

# save a file of all sequences and the respective cluster lables
if save_bool_filt == True:
    label_data_un_complete.to_csv(str(output_path_filt+'labels_summary_filt_complete.txt'), sep = '\t')

# create dictionary with all cluster numbers and the data with the sequences that occur in the target cluster with
# the binder sequence
dict_tar_un_complete = dict_target_cluster_seq_nr('complete', label_data_un_complete, range(20, 300, 20), 1069,
                                                  str(output_path_filt + 'Nr_seq_compl_filt.txt'),print_out = True, write_summary=False)

### NOTE ###
# complete linkage with 20 cluster centers was chosen for further analysis as the
# target cluster had ca. 200 sequences; see nr_seq_compl_filt.txt file
###########

# save data of the cluster of interest (cluster that contains the binder sequence) in the clustering summary folder
dict_tar_un_complete["tar_cluster_complete_20"].to_csv(output_path_summary + 'complete_20__filt/complete_20_target_cluster.txt', sep = '\t')





############################## AFFINITY PROPAGATION CLUSTERING DATA

#  (1) Load the clustering labels in a dataframe
cols = ['ReadID', 'Dataset', 'Boost', 'Cluster_label', 'CDR3_AA']
labels_AP = pd.DataFrame(columns=cols, dtype=np.int32)
labs = pd.read_csv(file_path_AP + 'aff_prop_cluster_labels.txt', index_col=0,
                    sep='\t', dtype=np.int32)
labels_AP.Cluster_label = labs.cluster_nr

target_seq = 'CTRDYYGSNYLAWFAYW'
# in labels we have a dataframe with all the Sequence indices and the according clusters
# we now want to add a column as the ReadIDs, Dataset and boost
# therefore we read the columns of the file, where all the CDR3 sequences are


labels_AP['ReadID'] = pd.read_csv(file_data_filt, sep = '\t', usecols=['ReadID'])
labels_AP['Dataset'] = pd.read_csv(file_data_filt, sep = '\t', usecols=['Dataset'])
labels_AP['Boost'] = pd.read_csv(file_data_filt, sep = '\t', usecols=['Boost'])
labels_AP['CDR3_AA'] = pd.read_csv(file_data_filt, sep = '\t', usecols=['CDR3_AA'])

# save the file with the cluster labels
labels_AP.to_csv(abs_path+'/data/Clustering/AP_clustering/labels_and_data_AP.txt', sep = '\t')

# Filter for the sequences in the cluster of the target sequence by comparing CDR3s with target CDR3
# find cluster of the binder sequence
labels_AP[labels_AP.CDR3_AA == target_seq]

## output:
#      ReadID Dataset  Boost  Cluster_label            CDR3_AA
#1069      34       A      3            118  CTRDYYGSNYLAWFAYW

# set the target cluster
n_tar_cluster = int(labels_AP.Cluster_label[labels_AP.CDR3_AA == target_seq])

tar_cluster_AP = pd.DataFrame(columns=cols)
tar_cluster_AP = labels_AP[labels_AP['Cluster_label'] == n_tar_cluster]

# print number of sequences in the target cluster  and in the other clusters
print('Nr. of sequences in target cluster, affinity propagation:' +
      str(len(tar_cluster_AP)))
# 32 sequences in the target cluster

tot_n_cluster = len(np.unique(labels_AP.Cluster_label))
# 198 clusters detected

for i in range(tot_n_cluster):
    print('Cluster: ' + str(i) + ' Nr. of sequences ' +
          str(len(labels_AP[labels_AP['Cluster_label']==i])))

# save the data
tar_cluster_AP.to_csv(abs_path + '/Clustering/AP_clustering/target_clust_data_AP.txt', sep = '\t')

