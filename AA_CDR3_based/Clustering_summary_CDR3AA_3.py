'''
Script to transfer the output generated by the Clustering scripts to a dataset
'''

import pandas as pd
import numpy as np


def load_labels(file_prefix, file_path_labels, file_data, cluster_range, n_sequences):
    '''
    Function to load the clustering output into a proper summarization file format;

    :param file_prefix: the prefix of the files to be loaded in the file path
    :param file_path: the path that contains the files with the indices of the sequences and the corr.
    cluster label
    :param cluster_range: range of cluster numbers that used in the clustering script
    :param n_sequences: number of sequences that were clustered
    :return: dataframe that contains the following columns: ['ReadID'], ['Dataset'], ['Boost'],
    ClusterNr_[cluster range], ['CDR3']
    '''
    # set the data names to load
    file_names = [str(file_prefix) + str(i) for i in cluster_range]

    # define the column names for the summarization data frame
    cols = ['ReadID'] + ['Dataset'] + ['Boost'] + ['ClusterNr_' + str(i) for i in cluster_range] + ['CDR3_AA']
    # initialize the dataframe
    df = pd.DataFrame(index=range(n_sequences), columns=cols, dtype=np.int32)

    # set the counter to access the right column of the dataframe
    i = 3
    # Load the data into the dataframe
    for file in file_names:
        data = pd.read_csv(str(file_path_labels + file + '.txt'), index_col=0, sep='\t', low_memory=True,
                           dtype=np.int32)
        df[df.columns[i]] = data
        i += 1

    # add the entries of the columns in the other columns from the file that contains the information about ReadID,
    # Dataset, Boost, and also the CDR3
    df['ReadID'] = pd.read_csv(file_data, sep='\t', usecols=['ReadID'])
    df['Dataset'] = pd.read_csv(file_data, sep='\t', usecols=['Dataset'])
    df['Boost'] = pd.read_csv(file_data, sep='\t', usecols=['Boost'])
    df['CDR3_AA'] = pd.read_csv(file_data, sep='\t', usecols=['CDR3_AA'])

    return df

def dict_target_cluster_seq_nr(linkage, cluster_input, cluster_range, tar_seq_index, file, print_out = False,
                               write_summary = False):
    '''
    Function to store a dataframe of the sequences that occur in the same cluster as the binder sequence in a
    dictionary with the keys of the cluster range and linkage
    :param cluster_input: dataframe from load_labels()
    :param cluster_range: range of cluster numbers that used in the clustering script
    :param tar_seq_index: index of the target sequence
    :return: dictionary with dataframes stored in the keys of the respective linkage and cluster number
    '''

    # Filter for the sequences in the cluster of the target sequence
    data_names = ['tar_cluster_' + str(linkage) + '_' + str(i) for i in cluster_range]


    # initialize list to store the dataframes of all the clusters
    dict = {}

    j = cluster_range
    for i in range(len(data_names)):

        # initialize dataframe to store data
        tar_cluster = cluster_input[cluster_input[str('ClusterNr_'+str(j[i]))] == cluster_input.iloc[tar_seq_index, i+3]]

        # reset index
        tar_cluster.reset_index(drop=True, inplace=True)
        # store the dataframe in the dictionary
        dict[data_names[i]] = tar_cluster

    # print number of sequences in the target cluster
    if print_out == True:
        print('Nr. of sequences in target cluster,', str(linkage), 'linkage:')
        for i in range(len(data_names)):
            print(linkage, cluster_range[i], ':', len(dict[data_names[i]]))

    if write_summary == True:
        with open(file, 'w') as f_out:
            f_out.write("Nr. of sequences in target cluster, {} linkage:\n".format(linkage))
            for i in range(len(data_names)):
                f_out.write("{} {}: {}\n".format(linkage, cluster_range[i], len(dict[data_names[i]])))

    return dict




#### SET INPUT FILE PATHS


# set file path for the data of the average linkage
file_path_av = '/media/lena/LENOVO/Dokumente/Masterarbeit/data/Clustering2/hierachical_clustering_ul2/'


########## (1) LENGTH FILTERED CDR3 SEQUENCE
# set file path for the data of the average linkage (CDR3 length filtered Clustering)
file_path_filt_av = '/media/lena/LENOVO/Dokumente/Masterarbeit/data/Clustering2/hierarchical_clustering_ul2/Cluster_labels/'
# set the filepath to the original file of the data of the length-filtered CDR3 sequences
file_data_filt = '/media/lena/LENOVO/Dokumente/Masterarbeit/data/Filtered_files2/data_uniq_length_uniqCDR3.txt'
# save the summary clustering file
save_bool_filt = True
# output path for the summary file
output_path_av_filt = '/media/lena/LENOVO/Dokumente/Masterarbeit/data/Clustering2/hierarchical_clustering_ul2/'


# set path to AFFINITY PORPAGATION clustering output file
file_path_AP = '/media/lena/LENOVO/Dokumente/Masterarbeit/data/Clustering2/AP_clustering/Cluster_labels/'

############################## NON FILTERED DATA

#  (1) Load the clustering labels (average linkage) in a dataframe
label_data_names = ['labels_cluster_average' + str(i) for i in range(50, 1000, 50)]
cols = ['ReadID']+['Dataset']+['Boost']+['ClusterNr_'+str(i) for i in range(50, 1000, 50)]+['CDR3_AA']
labels_all_average = pd.DataFrame(index=range(27077), columns=cols, dtype=np.int32)

data = pd.DataFrame()
i=3
for file in label_data_all:
    data = pd.read_csv(str(file_path_filt_av + 'Cluster_labels/' + file + '.txt'), index_col=0, sep='\t', low_memory=True,
                       dtype=np.int32)
    labels_all_average[labels_all_average.columns[i]] = data
    i=i+1

# in labels we have a dataframe with all the Sequence indices and the according clusters
# we now want to add a column as the ReadIDs, Dataset and boost
# therefore we read the columns of the file, where all the unique/united sequences are

file_path2 = '/media/lena/LENOVO/Dokumente/Masterarbeit/data/Clustering/'
labels_all_average['ReadID'] = pd.read_csv(str(file_path2+'data_uniqCDR3.txt'), sep = '\t', usecols=['ReadID'])
labels_all_average['Dataset'] = pd.read_csv(str(file_path2+'data_uniqCDR3.txt'), sep = '\t', usecols=['Dataset'])
labels_all_average['Boost'] = pd.read_csv(str(file_path2+'data_uniqCDR3.txt'), sep = '\t', usecols=['Boost'])
labels_all_average['CDR3_AA'] = pd.read_csv(str(file_path2+'data_uniqCDR3.txt'), sep = '\t', usecols=['CDR3_AA'])
# save the file with the clusterlabels
#labels_all_average.to_csv(str(file_path+'labels_summary_all_average.txt'), sep = '\t')

# Filter for the sequences in the cluster of the target sequence
tar_cluster_names_all_av = ['tar_cluster_all_average_'+str(i) for i in range(50, 1000, 50)]

j = range(50, 1000, 50)
for i in range(len(tar_cluster_names_all_av)):
    locals()[tar_cluster_names_all_av[i]] = pd.DataFrame(columns=cols)
    tar_cluster = labels_all_average[labels_all_average[str('ClusterNr_'+str(j[i]))] == labels_all_average.iloc[17358, i+3]]
    locals()[tar_cluster_names_all_av[i]] = tar_cluster
# print number of sequences in the target cluster
print('Nr. of sequences in target cluster, all CDR3s average linkage (from 50-950 clusters):')
for i in range(len(tar_cluster_names_all_av)):
    print(len(locals()[tar_cluster_names_all_av[i]]))

# save certain data of interest;
# tar_cluster_all_average_550.to_csv(str(file_path2 + '/Summary/average_550_nonfilt/average_labels_550.txt'), sep = '\t')


# (2) Load the clustering labels (complete linkage) in a dataframe
label_data_all = ['labels_cluster_complete' + str(i) for i in range(50, 1000, 50)]
cols = ['ReadID']+['Dataset']+['Boost']+['ClusterNr_'+str(i) for i in range(50, 1000, 50)]+['CDR3_AA']
labels_all_complete = pd.DataFrame(index=range(27077), columns=cols, dtype=np.int32)
file_path = '/media/lena/LENOVO/Dokumente/Masterarbeit/data/Clustering/Clustering_dist_matrix/'
data = pd.DataFrame()
i=3
for file in label_data_all:
    data = pd.read_csv(str(file_path + 'Cluster_labels_2/' + file + '.txt'), index_col=0, sep='\t', low_memory=True,
                       dtype=np.int32)
    labels_all_complete[labels_all_complete.columns[i]] = data
    i=i+1

# in labels we have a dataframe with all the Sequence indices and the according clusters
# we now want to add a column as the ReadIDs, Dataset and boost
# therefore we read the columns of the file, where all the unique/united sequences are

file_path2 = '/media/lena/LENOVO/Dokumente/Masterarbeit/data/Clustering/'
labels_all_complete['ReadID'] = pd.read_csv(str(file_path2+'data_uniq_length_CDR3.txt'), sep = '\t', usecols=['ReadID'])
labels_all_complete['Dataset'] = pd.read_csv(str(file_path2+'data_uniq_length_CDR3.txt'), sep = '\t', usecols=['Dataset'])
labels_all_complete['Boost'] = pd.read_csv(str(file_path2+'data_uniq_length_CDR3.txt'), sep = '\t', usecols=['Boost'])
labels_all_complete['CDR3_AA'] = pd.read_csv(str(file_path2+'data_uniq_length_CDR3.txt'), sep = '\t', usecols=['CDR3_AA'])
# save the file with the clusterlabels
#labels_all_complete.to_csv(str(file_path+'labels_summary_all_complete.txt'), sep = '\t')

tar_cluster_names_all_com = ['tar_cluster_all_complete_'+str(i) for i in range(50, 1000, 50)]

j = range(50, 1000, 50)
for i in range(len(tar_cluster_names_all_com)):
    locals()[tar_cluster_names_all_com[i]] = pd.DataFrame(columns=cols)
    tar_cluster = labels_all_complete[labels_all_complete[str('ClusterNr_'+str(j[i]))] == labels_all_complete.iloc[17358, i+3]]
    locals()[tar_cluster_names_all_com[i]] = tar_cluster
# print number of sequences in the target cluster
print('Nr. of sequences in target cluster, all CDR3s complete linkage (from 50-950 clusters):')
for i in range(len(tar_cluster_names_all_com)):
    print(len(locals()[tar_cluster_names_all_com[i]]))

# save certain data of interest;
# tar_cluster_all_complete_100.to_csv(str(file_path2 + 'Summary/complete_100_nonfilt/complete_labels_100.txt'), sep = '\t')






############################################### CDR3 LENGTH FILTERED DATA ## new range (20, 300, 200)

# (1) Load the clustering labels (average linkage) in a dataframe# Load the data
label_data_un_average = load_labels('labels_cluster_average', file_path_filt_av, file_data_filt, range(20, 300, 20), 1760)

# save a file with the summary file
if save_bool_filt == True:
    label_data_un_average.to_csv(str(output_path_av_filt+'labels_summary_unlength_average.txt'), sep = '\t')

# create dictionary with all cluster numbers and the data with the sequences that occur in the target cluster with
# the binder sequence
dict_tar_un_average = dict_target_cluster_seq_nr('average', label_data_un_average, range(20, 300, 20), 1069,
                                                 str(output_path_av_filt + 'Nr_seq_av_filt.txt'), print_out = True, write_summary=True)

# save certain data of the cluster of interest
# tar_cluster_average_60.to_csv(str(file_path + 'average_labels_60.txt'), sep = '\t')




# (2) Load the clustering labels (complete linkage) in a dataframe
label_data_un_complete = load_labels('labels_cluster_complete', file_path_filt_av, file_data_filt, range(20, 300, 20), 1760)

# save a file with the summary file
if save_bool_filt == True:
    label_data_un_complete.to_csv(str(output_path_av_filt+'labels_summary_unlength_complete.txt'), sep = '\t')

# create dictionary with all cluster numbers and the data with the sequences that occur in the target cluster with
# the binder sequence
dict_tar_un_complete = dict_target_cluster_seq_nr('complete', label_data_un_complete, range(20, 300, 20), 1069,
                                                  str(output_path_av_filt + 'Nr_seq_compl_filt.txt'),print_out = True, write_summary=True)

# save certain data of the cluster of interest if necessary
# tar_cluster_average_60.to_csv(str(file_path + 'average_labels_60.txt'), sep = '\t')





############################## AFFINITY PROPAGATION DATA

#  (1) Load the clustering labels in a dataframe
cols = ['ReadID']+['Dataset']+['Boost']+['Cluster_label']+['CDR3_AA']
labels_AP = pd.DataFrame(columns=cols, dtype=np.int32)
labs = pd.read_csv(str(file_path_AP + 'aff_prop_cluster_labels.txt'), index_col=0,
                        sep='\t', dtype=np.int32)
labels_AP.Cluster_label = labs.cluster_nr

target_seq = 'CTRDYYGSNYLAWFAYW'
# in labels we have a dataframe with all the Sequence indices and the according clusters
# we now want to add a column as the ReadIDs, Dataset and boost
# therefore we read the columns of the file, where all the unique/united sequences are

file_path2 = '/media/lena/LENOVO/Dokumente/Masterarbeit/data/Clustering/'
labels_AP['ReadID'] = pd.read_csv(str(file_path2+'data_uniq_length_CDR3.txt'), sep = '\t', usecols=['ReadID'])
labels_AP['Dataset'] = pd.read_csv(str(file_path2+'data_uniq_length_CDR3.txt'), sep = '\t', usecols=['Dataset'])
labels_AP['Boost'] = pd.read_csv(str(file_path2+'data_uniq_length_CDR3.txt'), sep = '\t', usecols=['Boost'])
labels_AP['CDR3_AA'] = pd.read_csv(str(file_path2+'data_uniq_length_CDR3.txt'), sep = '\t', usecols=['CDR3_AA'])
# save the file with the clusterlabels
labels_AP.to_csv(str(file_path2+'/Summary/affinity_propagation/labels_and_data_AP.txt'), sep = '\t')

# Filter for the sequences in the cluster of the target sequence by comparing CDR3s with target CDR3
labels_AP[labels_AP.CDR3_AA == target_seq]
#      ReadID Dataset  Boost  Cluster_label            CDR3_AA
#1069      34       A      3            118  CTRDYYGSNYLAWFAYW

# set the target cluster
n_tar_cluster = int(labels_AP.Cluster_label[labels_AP.CDR3_AA == target_seq])

tar_cluster_AP = pd.DataFrame(columns=cols)
tar_cluster_AP = labels_AP[labels_AP['Cluster_label'] == n_tar_cluster]

# print number of sequences in the target cluster  and in the other clusters
print('Nr. of sequences in target cluster, affinity propagation:' +
      str(len(tar_cluster_AP)))
# 549 sequences in the target cluster

tot_n_cluster = np.argmax(np.unique(labels_AP.Cluster_label))

for i in range(tot_n_cluster):
    print('Cluster: ' + str(i) + ' Nr. of sequences ' +
          str(len(labels_AP[labels_AP['Cluster_label']==i])))

# save the data
# tar_cluster_AP.to_csv(str(file_path2 + '/Affinity_propagation/target_clust_data_AP.txt'), sep = '\t')








################################################ OLD CODE ###############################################
# #  Load the clustering labels (complete linkage) in a dataframe
# label_data_ur = ['labels_cluster_complete' + str(i) for i in range(20, 300, 20)]
# cols = ['ReadID']+['Dataset']+['Boost']+['ClusterNr_'+str(i) for i in range(20, 300, 20)]+['CDR3_AA']
# labels_ur_complete = pd.DataFrame(index=range(1760), columns=cols, dtype=np.int32)
# file_path = '/media/lena/LENOVO/Dokumente/Masterarbeit/data/Clustering/Clustering_uniq_length_dist_matrix_20range/'
# data = pd.DataFrame()
# i=3
# for file in label_data_ur:
#     data = pd.read_csv(str(file_path + 'Cluster_labels/' + file + '.txt'), index_col=0, sep='\t', low_memory=True,
#                        dtype=np.int32)
#     labels_ur_complete[labels_ur_complete.columns[i]] = data
#     i=i+1
#
# # in labels we have a dataframe with all the Sequence indices and the according clusters
# # we now want to add a column as the ReadIDs, Dataset and boost
# # therefore we read the columns of the file, where all the unique/united sequences are
#
# file_path2 = '/media/lena/LENOVO/Dokumente/Masterarbeit/data/Clustering/'
# labels_ur_complete['ReadID'] = pd.read_csv(str(file_path2+'data_uniq_length_CDR3.txt'), sep = '\t', usecols=['ReadID'])
# labels_ur_complete['Dataset'] = pd.read_csv(str(file_path2+'data_uniq_length_CDR3.txt'), sep = '\t', usecols=['Dataset'])
# labels_ur_complete['Boost'] = pd.read_csv(str(file_path2+'data_uniq_length_CDR3.txt'), sep = '\t', usecols=['Boost'])
# labels_ur_complete['CDR3_AA'] = pd.read_csv(str(file_path2+'data_uniq_length_CDR3.txt'), sep = '\t', usecols=['CDR3_AA'])
# # save the file with the clusterlabels
# # labels_ur_complete.to_csv(str(file_path+'labels_summary_unlength_20range_complete.txt'), sep = '\t')
#
# tar_cluster_names_ur_com = ['tar_cluster_complete_'+str(i) for i in range(20, 300, 20)]
#
# j = range(20, 300, 20)
# for i in range(len(tar_cluster_names_ur_com)):
#     locals()[tar_cluster_names_ur_com[i]] = pd.DataFrame(columns=cols)
#     tar_cluster = labels_ur_complete[labels_ur_complete[str('ClusterNr_'+str(j[i]))] == labels_ur_complete.iloc[1069, i+3]]
#     locals()[tar_cluster_names_ur_com[i]] = tar_cluster
# # print number of sequences in the target cluster
# print('Nr. of sequences in target cluster,length filtered complete linkage (from 20-280 clusters):')
# for i in range(len(tar_cluster_names_ur_com)):
#     print(len(locals()[tar_cluster_names_ur_com[i]]))

# save certain data of interest;
# tar_cluster_complete_280.to_csv(str(file_path + 'complete_labels_280.txt'), sep = '\t')

##################################################################################################