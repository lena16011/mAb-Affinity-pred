'''
Script to calculating some statistics from the VDJ sequences that were generated by randomly sampling
combinations of mutations and predicted.
'''


import pandas as pd
import stringdist
import numpy as np



# calculate a distance matrix
def calculate_norm_dist_matrix(seq_lst):
    '''
    function to calculate the distance matrix for further k-Medoids clustering
    seq_lst is a list of the input sequences for pairwise distance calculation
    :return: is a pandas dataframe of all distances of the n input sequences to each other;
             the lower triangular of the matrix is filled;
    '''
    # initialize numpy 2d array for the matrix
    seqs = pd.Series(np.array(seq_lst))
    D = pd.DataFrame(columns=range(len(seqs)))
    row = pd.DataFrame(columns=range(len(seqs)))
    for i, seq in enumerate(seqs):
        # Calculate the distances as rows of the distance matrix
        row = seqs.iloc[:].apply(stringdist.levenshtein_norm, args=(seqs.loc[i],))
        D.loc[i] = row.T
        print(i)
    return D.values

# calculate a distance matrix
def calculate_LD_dist_matrix(seq_lst):
    '''
    function to calculate the distance matrix for further k-Medoids clustering
    seq_lst is a list of the input sequences for pairwise distance calculation
    :return: is a pandas dataframe of all distances of the n input sequences to each other;
             the lower triangular of the matrix is filled;
    '''
    # initialize numpy 2d array for the matrix
    seqs = pd.Series(np.array(seq_lst))
    D = pd.DataFrame(columns=range(len(seqs)))
    row = pd.DataFrame(columns=range(len(seqs)))
    for i, seq in enumerate(seqs):
        # Calculate the distances as rows of the distance matrix
        row = seqs.iloc[:].apply(stringdist.levenshtein, args=(seqs.loc[i],))
        D.loc[i] = row.T
        print(i)
    return D.values

# prepare the sequence list for the network plots; create 3-tuples; just from another script
# re-used to calculate some statistics
def ebunch_LD(seqs_lst, dist_matrix, LD = None):
    '''
        Function to calculate the distance matrix (Levenshtein distance) and then store the
        sequence pairs as 3-tuples with the connected sequences and their corresponding
        Levenshtein distance;

        - seq_lst is a list of the input sequences for pairwise distance calculation
        - LD is the Levenshtein distance of which want the function to return the ebunches
        :return ebunch : is a list of 3-tuples;
    '''

    # initialize numpy 2d array for the matrix
    seqs = pd.Series(np.array(seqs_lst))
    D = pd.DataFrame(dist_matrix)


    # now we can store the 3-tuples with the distances as weights (ebunch for the network graph)
    data_tup = []
    for i in range(len(seqs_lst)):
        for j in range(i + 1, len(seqs_lst)):
            if LD !=None:
                if D.iloc[j, i] == LD:
                    val = (i, j, D.iloc[j, i])
                    data_tup.append(val)
            elif LD == None:
                val = (i, j, D.iloc[j, i])
                data_tup.append(val)
    return data_tup


def ebunch_norm(seqs_lst, dist_matrix, LD = None):
    '''
        Function to calculate the distance matrix (Levenshtein distance) and then store the
        sequence pairs as 3-tuples with the connected sequences and their corresponding
        Levenshtein distance;

        - seq_lst is a list of the input sequences for pairwise distance calculation
        - LD is the Levenshtein distance of which want the function to return the ebunches
        :return ebunch : is a list of 3-tuples;
    '''

    # initialize numpy 2d array for the matrix
    seqs = pd.Series(np.array(seqs_lst))
    D = pd.DataFrame(dist_matrix)

    # now we can store the 3-tuples with the distances as weights (ebunch for the network graph)
    data_tup = []
    for i in range(len(seqs_lst)):
        for j in range(i + 1, len(seqs_lst)):
            if LD !=None:
                if D.iloc[j, i] == LD:
                    val = (i, j, D.iloc[j, i])
                    data_tup.append(val)
            elif LD == None:
                val = (i, j, D.iloc[j, i])
                data_tup.append(val)
    return data_tup




## Set input directories

in_dir = '/media/lena/LENOVO/Dokumente/Masterarbeit/data/GP/gen_seqs_muvar/pos/'
in_file = in_dir + 'new_seq_gen_pos.csv'

## load data from generated/predicted sequences

data = pd.read_csv(in_file, index_col=0)
data.sort_values(by='mus', inplace = True, ascending=False)

# save top 1000 sequences
data_save = data.iloc[:1000, ]
data_save.to_csv(in_dir + 'top_1000_pos.csv')

### Calculate distance matrices

# get the first sequences as list (with lowest KD)
seq_lst = list(data.Sequences[:1000])


# calculate norm distance matrix
dist_norm = calculate_norm_dist_matrix(seq_lst)

# save normal. distance matrix and save
np.savetxt(in_dir+'dist_matrix_1000_hiKDs.csv', dist_norm, delimiter = ',')

# calculate LD distance matrix and save
dist_LD = calculate_LD_dist_matrix(seq_lst)
np.savetxt(in_dir+'LDdist_matrix_1000_hiKDs.csv', dist_norm, delimiter = ',')


# create ebunches to calculate statistics
eb = ebunch_LD(seq_lst, dist_LD)
mean_LD = np.mean([eb[x][2] for x in range(len(eb))])
max_LD = max([eb[x][2] for x in range(len(eb))])

# similarity
eb_norm = ebunch_norm(seq_lst, dist_norm)
mean_sim = 1 - np.mean([eb_norm[x][2] for x in range(len(eb_norm))])
min_sim = min([1-eb_norm[x][2] for x in range(len(eb_norm))])
max_sim = max([1-eb_norm[x][2] for x in range(len(eb_norm))])


# print the stats
print("# selected VDJs",'\t',len(dist_LD))
print("length of VDJs",'\t',np.unique([len(x) for x in seq_lst]))

print("range of selected LDs",'\t',np.unique(dist_LD))
print("mean LD",'\t',round(mean_LD, 1))
print("max LD",'\t',max_LD)

print("mean Similarity",'\t', str(round(mean_sim, 3)))
print("min Similarity",'\t',str(round(min_sim, 3)))
print("max Similarity",'\t',str(round(max_sim, 3)))

# print a sequence list
[print(x) for x in seq_lst]














